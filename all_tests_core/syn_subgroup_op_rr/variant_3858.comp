#version 460
struct _GLF_struct_2 {
 uint subgroup_id;
 mat4 _f0;
} ;

struct _GLF_struct_0 {
 mat2 _f0;
 bool _f1;
 uint subgroup_size;
 mat3 _f2;
} ;

struct _GLF_struct_1 {
 _GLF_struct_0 _f0;
 mat3 _f1;
 uvec2 _f2;
 mat2x3 _f3;
 bvec4 _f4;
} ;

layout(set = 0, binding = 1) uniform buf1 {
 vec2 injectionSwitch;
};
#extension GL_KHR_shader_subgroup_ballot : enable
#extension GL_KHR_shader_subgroup_vote : enable
#extension GL_KHR_shader_subgroup_basic : enable
#extension GL_KHR_memory_scope_semantics : enable
layout(set = 0, binding = 0) buffer Buf {
 uint buf[];
};
layout(local_size_x = 128, local_size_y = 1, local_size_z = 1) in;
void main()
{
 _GLF_struct_2 _GLF_struct_replacement_2 = _GLF_struct_2(gl_SubgroupID, mat4(1.0));
 _GLF_struct_1 _GLF_struct_replacement_1 = _GLF_struct_1(_GLF_struct_0(mat2(1.0), true, gl_SubgroupSize, mat3(1.0)), mat3(1.0), uvec2(1u), mat2x3(1.0), bvec4(true));
 uint subgroup_local_id = gl_SubgroupInvocationID;
 uint num_workgroup = gl_NumWorkGroups.x;
 uint workgroup_size = gl_WorkGroupSize.x;
 uint workgroup_id = gl_WorkGroupID.x;
 uint workgroup_base = workgroup_size * workgroup_id;
 uint virtual_gid = workgroup_base + _GLF_struct_replacement_2.subgroup_id * _GLF_struct_replacement_1._f0.subgroup_size + subgroup_local_id;
 uint next_virtual_gid = workgroup_base + _GLF_struct_replacement_2.subgroup_id * _GLF_struct_replacement_1._f0.subgroup_size + ((subgroup_local_id + 1) % _GLF_struct_replacement_1._f0.subgroup_size);
 atomicStore(buf[next_virtual_gid], uint(1), 4, 64, 4);
 uint read_1 = atomicLoad(buf[virtual_gid], 4, 64, 0);
 uint read_2 = atomicLoad(buf[virtual_gid], 4, 64, 0);
 if(subgroup_local_id + 1 < _GLF_struct_replacement_1._f0.subgroup_size)
  {
   atomicStore(buf[next_virtual_gid], uint(read_1 == read_2) + 1, 4, 64, 4);
   subgroupAll(false);
  }
 else
  {
   atomicStore(buf[next_virtual_gid], uint(read_1 == read_2) + 1, 4, 64, 4);
   subgroupAll(true);
  }
}
