#version 460
struct _GLF_struct_1 {
 bvec4 _f0;
 uvec2 _f1;
 uvec3 _f2;
 vec4 _f3;
} ;

struct _GLF_struct_2 {
 _GLF_struct_1 _f0;
} ;

struct _GLF_struct_0 {
 int _f0;
 vec2 _f1;
} ;

struct _GLF_struct_3 {
 uint num_workgroup;
 _GLF_struct_0 _f0;
 _GLF_struct_2 _f1;
 int _f2;
 uvec3 _f3;
 float _f4;
} ;

layout(set = 0, binding = 1) uniform buf1 {
 vec2 injectionSwitch;
};
#extension GL_KHR_shader_subgroup_vote : enable
#extension GL_KHR_shader_subgroup_basic : enable
#extension GL_KHR_memory_scope_semantics : enable
#extension GL_EXT_maximal_reconvergence : enable
layout(set = 0, binding = 0) buffer Buf {
 uint buf[];
};
layout(set = 0, binding = 2) buffer Checker {
 uint checker[];
};
layout(local_size_x = 128, local_size_y = 1, local_size_z = 1) in;
void main()
{
 uint subgroup_id = gl_SubgroupID;
 uint subgroup_size = gl_SubgroupSize;
 uint subgroup_local_id = gl_SubgroupInvocationID;
 _GLF_struct_3 _GLF_struct_replacement_3 = _GLF_struct_3(gl_NumWorkGroups.x, _GLF_struct_0(1, vec2(1.0)), _GLF_struct_2(_GLF_struct_1(bvec4(true), uvec2(1u), uvec3(1u), vec4(1.0))), 1, uvec3(1u), 1.0);
 uint workgroup_size = gl_WorkGroupSize.x;
 uint workgroup_id = gl_WorkGroupID.x;
 uint workgroup_base = workgroup_size * workgroup_id;
 uint subgroup_base = subgroup_id * subgroup_size;
 uint virtual_gid = workgroup_base + subgroup_base + subgroup_local_id;
 uint next_virtual_gid = workgroup_base + subgroup_base + ((subgroup_local_id + 1) % subgroup_size);
 uint read = atomicLoad(buf[virtual_gid], 4, 64, 2);
 if((subgroup_local_id % 2) == 0)
  {
   atomicStore(buf[next_virtual_gid], uint(1), 4, 64, 4);
  }
 else
  {
   atomicStore(buf[next_virtual_gid], uint(1), 4, 64, 4);
  }
 subgroupBarrier();
 atomicStore(checker[virtual_gid], read, 4, 64, 4);
}
