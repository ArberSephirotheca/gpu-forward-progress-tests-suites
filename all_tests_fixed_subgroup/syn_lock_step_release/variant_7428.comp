#version 460

#ifndef REDUCER
#define _GLF_ZERO(X, Y)                   (Y)
#define _GLF_ONE(X, Y)                    (Y)
#define _GLF_FALSE(X, Y)                  (Y)
#define _GLF_TRUE(X, Y)                   (Y)
#define _GLF_IDENTITY(X, Y)               (Y)
#define _GLF_DEAD(X)                      (X)
#define _GLF_FUZZED(X)                    (X)
#define _GLF_WRAPPED_LOOP(X)              X
#define _GLF_WRAPPED_IF_TRUE(X)           X
#define _GLF_WRAPPED_IF_FALSE(X)          X
#define _GLF_SWITCH(X)                    X
#define _GLF_MAKE_IN_BOUNDS_INT(IDX, SZ)  clamp(IDX, 0, SZ - 1)
#define _GLF_MAKE_IN_BOUNDS_UINT(IDX, SZ) clamp(IDX, 0u, SZ - 1u)
#endif


struct _GLF_struct_13 {
 uvec3 _f0;
 uint _f1;
 vec4 _f2;
 mat2x3 _f3;
 uvec4 _f4;
} ;

struct _GLF_struct_12 {
 mat4x2 _f0;
 vec3 _f1;
} ;

struct _GLF_struct_14 {
 _GLF_struct_12 _f0;
 _GLF_struct_13 _f1;
 vec3 _f2;
 mat4x2 _f3;
} ;

struct _GLF_struct_10 {
 float _f0;
 vec3 _f1;
 ivec4 _f2;
 mat2x3 _f3;
} ;

struct _GLF_struct_11 {
 mat3x4 _f0;
 vec3 _f1;
 _GLF_struct_10 _f2;
} ;

struct _GLF_struct_8 {
 ivec4 _f0;
 mat3x2 _f1;
 float _f2;
 bvec2 _f3;
 mat3x4 _f4;
 uint _f5;
} ;

struct _GLF_struct_9 {
 _GLF_struct_8 _f0;
} ;

struct _GLF_struct_15 {
 uint next_virtual_gid;
 _GLF_struct_9 _f0;
 _GLF_struct_11 _f1;
 _GLF_struct_14 _f2;
 ivec4 _f3;
} ;

struct _GLF_struct_7 {
 bvec4 _f0;
 vec2 _f1;
 uint workgroup_size;
} ;

struct _GLF_struct_4 {
 int _f0;
 mat4x2 _f1;
 uvec4 _f2;
 mat3x2 _f3;
 bvec2 _f4;
 mat2 _f5;
} ;

struct _GLF_struct_3 {
 uint num_workgroup;
 float _f0;
 ivec2 _f1;
 bool _f2;
} ;

struct _GLF_struct_5 {
 bvec4 _f0;
 _GLF_struct_3 _f1;
 uvec4 _f2;
 _GLF_struct_4 _f3;
} ;

struct _GLF_struct_1 {
 uvec2 _f0;
 vec3 _f1;
 uvec3 _f2;
} ;

struct _GLF_struct_0 {
 vec4 _f0;
 mat3x4 _f1;
 ivec2 _f2;
 mat3x2 _f3;
 float _f4;
 uvec3 _f5;
} ;

struct _GLF_struct_2 {
 bvec4 _f0;
 _GLF_struct_0 _f1;
 _GLF_struct_1 _f2;
 bvec4 _f3;
} ;

struct _GLF_struct_6 {
 _GLF_struct_2 _f0;
 _GLF_struct_5 _f1;
} ;

layout(set = 0, binding = 1) uniform buf1 {
 vec2 injectionSwitch;
};
#extension GL_KHR_shader_subgroup_ballot : enable
#extension GL_KHR_shader_subgroup_vote : enable
#extension GL_KHR_shader_subgroup_basic : enable
#extension GL_KHR_memory_scope_semantics : enable
layout(set = 0, binding = 0) buffer Buf {
 uint buf[];
};
layout(local_size_x = 128, local_size_y = 1, local_size_z = 1) in;
void main()
{
 uint subgroup_id = gl_SubgroupID;
uint subgroup_size = 16;
 if(_GLF_DEAD(false))
  {
   if(_GLF_DEAD(false))
    return;
   return;
  }
 if(_GLF_DEAD(false))
  return;
 uint subgroup_local_id = gl_SubgroupInvocationID;
 _GLF_struct_6 _GLF_struct_replacement_6 = _GLF_struct_6(_GLF_struct_2(bvec4(true), _GLF_struct_0(vec4(1.0), mat3x4(1.0), ivec2(1), mat3x2(1.0), 1.0, uvec3(1u)), _GLF_struct_1(uvec2(1u), vec3(1.0), uvec3(1u)), bvec4(true)), _GLF_struct_5(bvec4(true), _GLF_struct_3(gl_NumWorkGroups.x, 1.0, ivec2(1), true), uvec4(1u), _GLF_struct_4(1, mat4x2(1.0), uvec4(1u), mat3x2(1.0), bvec2(true), mat2(1.0))));
 _GLF_struct_7 _GLF_struct_replacement_7 = _GLF_struct_7(bvec4(true), vec2(1.0), gl_WorkGroupSize.x);
 uint workgroup_id = gl_WorkGroupID.x;
 uint workgroup_base = _GLF_struct_replacement_7.workgroup_size * workgroup_id;
 if(_GLF_DEAD(false))
  return;
 uint virtual_gid = workgroup_base + subgroup_id * subgroup_size + subgroup_local_id;
 if(_GLF_DEAD(_GLF_FALSE(false, (injectionSwitch.x > injectionSwitch.y))))
  return;
 _GLF_struct_15 _GLF_struct_replacement_15 = _GLF_struct_15(workgroup_base + subgroup_id * subgroup_size + ((subgroup_local_id + 1) % subgroup_size), _GLF_struct_9(_GLF_struct_8(ivec4(1), mat3x2(1.0), 1.0, bvec2(true), mat3x4(1.0), 1u)), _GLF_struct_11(mat3x4(1.0), vec3(1.0), _GLF_struct_10(1.0, vec3(1.0), ivec4(1), mat2x3(1.0))), _GLF_struct_14(_GLF_struct_12(mat4x2(1.0), vec3(1.0)), _GLF_struct_13(uvec3(1u), 1u, vec4(1.0), mat2x3(1.0), uvec4(1u)), vec3(1.0), mat4x2(1.0)), ivec4(1));
 buf[virtual_gid] = 1;
 atomicStore(buf[_GLF_struct_replacement_15.next_virtual_gid], uint(2), 4, 64, 4);
 if(_GLF_DEAD(false))
  return;
}
